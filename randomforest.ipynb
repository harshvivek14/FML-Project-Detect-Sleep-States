{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n","# We will use Random Forest Classifier here with Hyperparameters."]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color:green;\">Importing data</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-27T12:16:11.071487Z","iopub.status.busy":"2023-11-27T12:16:11.071003Z","iopub.status.idle":"2023-11-27T12:16:11.086708Z","shell.execute_reply":"2023-11-27T12:16:11.084678Z","shell.execute_reply.started":"2023-11-27T12:16:11.071452Z"},"trusted":true},"outputs":[],"source":["%%time\n","\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import polars as pl\n","import datetime \n","from tqdm import tqdm\n","\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import plotly.graph_objects as go\n","\n","from metric import score \n","\n","\n","column_names = {\n","    'series_id_column_name': 'series_id',\n","    'time_column_name': 'step',\n","    'event_column_name': 'event',\n","    'score_column_name': 'score',\n","}\n","\n","tolerances = {\n","    'onset': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360], \n","    'wakeup': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360]\n","}\n","tolerances"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-27T12:16:11.090839Z","iopub.status.busy":"2023-11-27T12:16:11.090217Z","iopub.status.idle":"2023-11-27T12:16:11.171184Z","shell.execute_reply":"2023-11-27T12:16:11.169563Z","shell.execute_reply.started":"2023-11-27T12:16:11.090789Z"},"trusted":true},"outputs":[],"source":["# converting the data into python readbale form\n","%%time \n","\n","dt_transforms = [\n","    pl.col('timestamp').str.to_datetime(), \n","    (pl.col('timestamp').str.to_datetime().dt.year()-2000).cast(pl.UInt8).alias('year'), \n","    pl.col('timestamp').str.to_datetime().dt.month().cast(pl.UInt8).alias('month'),\n","    pl.col('timestamp').str.to_datetime().dt.day().cast(pl.UInt8).alias('day'), \n","    pl.col('timestamp').str.to_datetime().dt.hour().cast(pl.UInt8).alias('hour')\n","]\n","\n","data_transforms = [\n","    pl.col('anglez').cast(pl.Int16), # Casting anglez to 16 bit integer\n","    (pl.col('enmo')*1000).cast(pl.UInt16), # Convert enmo to 16 bit uint\n","]\n","\n","train_series = pl.scan_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet').with_columns(\n","    dt_transforms + data_transforms\n","    )\n","\n","train_events = pl.read_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv').with_columns(\n","    dt_transforms\n","    )\n","\n","test_series = pl.scan_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet').with_columns(\n","    dt_transforms + data_transforms\n","    )\n","\n","# Getting series ids as a list for convenience\n","series_ids = train_events['series_id'].unique(maintain_order=True).to_list()\n","print(len(series_ids))\n","\n","# Removing series with mismatched counts: \n","onset_counts = train_events.filter(pl.col('event')=='onset').group_by('series_id').count().sort('series_id')['count']\n","wakeup_counts = train_events.filter(pl.col('event')=='wakeup').group_by('series_id').count().sort('series_id')['count']\n","\n","\n","counts = pl.DataFrame({'series_id':sorted(series_ids), 'onset_counts':onset_counts, 'wakeup_counts':wakeup_counts})\n","count_mismatches = counts.filter(counts['onset_counts'] != counts['wakeup_counts'])\n","\n","train_series = train_series.filter(~pl.col('series_id').is_in(count_mismatches['series_id']))\n","train_events = train_events.filter(~pl.col('series_id').is_in(count_mismatches['series_id']))\n","\n","# Updating list of series ids, not including series with no non-null values.\n","series_ids = train_events.drop_nulls()['series_id'].unique(maintain_order=True).to_list()\n","len(series_ids)"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color:green;\">Feature Engineering</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-27T12:16:11.174511Z","iopub.status.busy":"2023-11-27T12:16:11.173962Z","iopub.status.idle":"2023-11-27T12:16:11.194514Z","shell.execute_reply":"2023-11-27T12:16:11.191741Z","shell.execute_reply.started":"2023-11-27T12:16:11.174465Z"},"trusted":true},"outputs":[],"source":["#smoothing data nad creating more features from the avilable\n","\n","%%time\n","features, feature_cols = [pl.col('hour')], ['hour']\n","\n","for mins in [5, 30, 60*2, 60*8] :\n","    features += [\n","        pl.col('enmo').rolling_mean(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'enmo_{mins}m_mean'),\n","        pl.col('enmo').rolling_max(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'enmo_{mins}m_max')\n","    ]\n","\n","    feature_cols += [ \n","        f'enmo_{mins}m_mean', f'enmo_{mins}m_max'\n","    ]\n","\n","    # Getting first variations\n","    for var in ['enmo', 'anglez'] :\n","        features += [\n","            (pl.col(var).diff().abs().rolling_mean(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_mean'),\n","            (pl.col(var).diff().abs().rolling_max(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_max')\n","        ]\n","\n","        feature_cols += [ \n","            f'{var}_1v_{mins}m_mean', f'{var}_1v_{mins}m_max'\n","        ]\n","    \n","#     var1='enmo'\n","#     var2='anglez'\n","#     features += [\n","#             ((pl.col(var1).diff().abs().rolling_mean(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32)*(pl.col(var2).diff().abs().rolling_mean(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32)).alias(f'product_1v_{mins}m_mean'),\n","#             ((pl.col(var1).diff().abs().rolling_max(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32)*(pl.col(var2).diff().abs().rolling_max(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32)).alias(f'product_1v_{mins}m_mean')\n","#         ]\n","#     feature_cols += [ \n","#             f'product_1v_{mins}m_mean', f'product_1v_{mins}m_max'\n","#         ]\n","    \n","\n","id_cols = ['series_id', 'step', 'timestamp']\n","\n","train_series = train_series.with_columns(\n","    features\n",").select(id_cols + feature_cols)\n","\n","test_series = test_series.with_columns(\n","    features\n",").select(id_cols + feature_cols)\n","\n","print(\"finished\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-27T12:16:11.199247Z","iopub.status.busy":"2023-11-27T12:16:11.198660Z","iopub.status.idle":"2023-11-27T12:16:11.215311Z","shell.execute_reply":"2023-11-27T12:16:11.213347Z","shell.execute_reply.started":"2023-11-27T12:16:11.199198Z"},"trusted":true},"outputs":[],"source":["%%time\n","\n","def make_train_dataset(train_data, train_events, drop_nulls=False) :\n","    \n","    series_ids = train_data['series_id'].unique(maintain_order=True).to_list()\n","    X, y = pl.DataFrame(), pl.DataFrame()\n","    for idx in tqdm(series_ids) : \n","        \n","        # Normalizing sample features\n","        sample = train_data.filter(pl.col('series_id')==idx).with_columns(\n","            [(pl.col(col) / pl.col(col).std()).cast(pl.Float32) for col in feature_cols if col != 'hour']\n","        )\n","        \n","        events = train_events.filter(pl.col('series_id')==idx)\n","        \n","        if drop_nulls : \n","            # Removing datapoints on dates where no data was recorded\n","            sample = sample.filter(\n","                pl.col('timestamp').dt.date().is_in(events['timestamp'].dt.date())\n","            )\n","        \n","        X = X.vstack(sample[id_cols + feature_cols])\n","\n","        onsets = events.filter((pl.col('event') == 'onset') & (pl.col('step') != None))['step'].to_list()\n","        wakeups = events.filter((pl.col('event') == 'wakeup') & (pl.col('step') != None))['step'].to_list()\n","\n","        # NOTE: This will break if there are event series without any recorded onsets or wakeups\n","        y = y.vstack(sample.with_columns(\n","            sum([(onset <= pl.col('step')) & (pl.col('step') <= wakeup) for onset, wakeup in zip(onsets, wakeups)]).cast(pl.Boolean).alias('asleep')\n","            ).select('asleep')\n","            )\n","    \n","    y = y.to_numpy().ravel()\n","    \n","    return X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-27T12:16:11.219137Z","iopub.status.busy":"2023-11-27T12:16:11.218556Z","iopub.status.idle":"2023-11-27T12:16:11.239622Z","shell.execute_reply":"2023-11-27T12:16:11.237828Z","shell.execute_reply.started":"2023-11-27T12:16:11.219089Z"},"trusted":true},"outputs":[],"source":["%%time\n","def get_events(series, classifier) :\n","    '''\n","    Takes a time series and a classifier and returns a formatted submission dataframe.\n","    '''\n","    \n","    series_ids = series['series_id'].unique(maintain_order=True).to_list()\n","    events = pl.DataFrame(schema={'series_id':str, 'step':int, 'event':str, 'score':float})\n","\n","    for idx in tqdm(series_ids) : \n","\n","        # Collecting sample and normalizing features\n","        scale_cols = [col for col in feature_cols if (col != 'hour') & (series[col].std() !=0)]\n","        X = series.filter(pl.col('series_id') == idx).select(id_cols + feature_cols).with_columns(\n","            [(pl.col(col) / series[col].std()).cast(pl.Float32) for col in scale_cols]\n","        )\n","\n","        # Applying classifier to get predictions and scores\n","        preds, probs = classifier.predict(X[feature_cols]), classifier.predict_proba(X[feature_cols])[:, 1]\n","\n","        #NOTE: Considered using rolling max to get sleep periods excluding <30 min interruptions, but ended up decreasing performance\n","        X = X.with_columns(\n","            pl.lit(preds).cast(pl.Int8).alias('prediction'), \n","            pl.lit(probs).alias('probability')\n","                        )\n","        \n","        # Getting predicted onset and wakeup time steps\n","        pred_onsets = X.filter(X['prediction'].diff() > 0)['step'].to_list()\n","        pred_wakeups = X.filter(X['prediction'].diff() < 0)['step'].to_list()\n","        \n","        if len(pred_onsets) > 0 : \n","            \n","            # Ensuring all predicted sleep periods begin and end\n","            if min(pred_wakeups) < min(pred_onsets) : \n","                pred_wakeups = pred_wakeups[1:]\n","\n","            if max(pred_onsets) > max(pred_wakeups) :\n","                pred_onsets = pred_onsets[:-1]\n","\n","            # Keeping sleep periods longer than 30 minutes\n","            sleep_periods = [(onset, wakeup) for onset, wakeup in zip(pred_onsets, pred_wakeups) if wakeup - onset >= 12 * 30]\n","\n","            for onset, wakeup in sleep_periods :\n","                # Scoring using mean probability over period\n","                score = X.filter((pl.col('step') >= onset) & (pl.col('step') <= wakeup))['probability'].mean()\n","\n","                # Adding sleep event to dataframe\n","                events = events.vstack(pl.DataFrame().with_columns(\n","                    pl.Series([idx, idx]).alias('series_id'), \n","                    pl.Series([onset, wakeup]).alias('step'),\n","                    pl.Series(['onset', 'wakeup']).alias('event'),\n","                    pl.Series([score, score]).alias('score')\n","                ))\n","\n","    # Adding row id column\n","    events = events.to_pandas().reset_index().rename(columns={'index':'row_id'})\n","\n","    return events"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color:orange;\">Training Models</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-27T12:16:11.242353Z","iopub.status.busy":"2023-11-27T12:16:11.241878Z"},"trusted":true},"outputs":[],"source":["# reducing the data significantly\n","\n","%%time\n","from sklearn.model_selection import train_test_split\n","\n","# print(series_ids)\n","\n","train_ids, val_ids = train_test_split(series_ids, train_size=0.7, random_state=42)\n","\n","# # We will collect datapoints at 15 minute intervals for training for validating\n","train_data = train_series.filter(pl.col('series_id').is_in(train_ids)).take_every(12 * 15).collect()\n","val_data = train_series.filter(pl.col('series_id').is_in(val_ids)).take_every(12 * 15).collect()\n","\n","print(\"finished\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","# Creating train dataset\n","X_train, y_train = make_train_dataset(train_data, train_events)\n","print(X_train.head())\n","print(X_train.columns)"]},{"cell_type":"markdown","metadata":{},"source":["<h3 style=\"color:blue;\">Training and validating random forest</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","# calssifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Training classifier\n","rf_classifier = RandomForestClassifier(n_estimators=5, \n","                                    min_samples_leaf=20, \n","                                    random_state=42,\n","                                    n_jobs=-1)\n","\n","rf_classifier.fit(X_train[feature_cols], y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","# Checking performance on validation set\n","rf_submission = get_events(val_data, rf_classifier)\n","\n","print(f\"Random forest score: {score(val_solution, rf_submission, tolerances, **column_names)}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6589269,"sourceId":53666,"sourceType":"competition"},{"datasetId":3706667,"sourceId":6507308,"sourceType":"datasetVersion"},{"sourceId":151583600,"sourceType":"kernelVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
